{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/ml1/.fastai/data/mnist_tiny/train/7'),Path('/home/ml1/.fastai/data/mnist_tiny/train/3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            if len(folders) !=0 and i==0 and '.' not in folders: continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/home/ml1/.fastai/data/mnist_tiny/train/7/934.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/8845.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/7731.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/9774.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/9434.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/9395.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/8237.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/7287.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/8629.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/79.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ItemGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `itemgetter(i)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, i): self.i = i\n",
    "    def encodes(self, x): return x[self.i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ItemGetter(1)((1,2,3)),  2)\n",
    "test_eq(ItemGetter(1)(L(1,2,3)), 2)\n",
    "test_eq(ItemGetter(1)([1,2,3]),  2)\n",
    "test_eq(ItemGetter(1)(np.array([1,2,3])),  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AttrGetter(ItemTransform):\n",
    "    \"Creates a proper transform that applies `attrgetter(nm)` (even on a tuple)\"\n",
    "    _retain = False\n",
    "    def __init__(self, nm, default=None): store_attr(self, 'nm,default')\n",
    "    def encodes(self, x): return getattr(x, self.nm, self.default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(AttrGetter('shape')(torch.randn([4,5])), [4,5])\n",
    "test_eq(AttrGetter('shape', [0])([4,5]), [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn train_test_split. This allow to *split* items in a stratified fashion (uniformely according to the ‘labels‘ distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, **kwargs):\n",
    "    \"Split `items` into random train and test subsets using sklearn train_test_split utility.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train, valid = train_test_split(range(len(o)), test_size=test_size, random_state=random_state, stratify=stratify, **kwargs)\n",
    "        return L(train), L(valid)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "labels = [0] * 20 + [1] * 10\n",
    "test_size = 0.2\n",
    "\n",
    "f = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)\n",
    "\n",
    "# test labels distribution consistency\n",
    "# there should be test_size % of zeroes and ones respectively in the validation set\n",
    "test_eq(len([t for t in val if t < 20]) / 20, test_size)\n",
    "test_eq(len([t for t in val if t > 20]) / 10, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name):\n",
    "    def _inner(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)\n",
    "    return [i for n in L(name) for i in _inner(items,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames2 = fnames + [path/'test/3/4256.png', path/'test/7/2345.png', path/'valid/7/6467.png']\n",
    "splitter = GrandparentSplitter(train_name=('train', 'valid'), valid_name='test')\n",
    "test_eq(splitter(fnames2),[[0,3,4,6,1,2,5,7,10],[8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o, **kwargs): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    valid = Path(fname).read().split('\\n')\n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o, **kwargs):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = (o.iloc[:,col] if isinstance(col, int) else o[col]).values\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])\n",
    "#Works with strings or index\n",
    "splits = ColSplitter(1)(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSubsetSplitter(train_sz, valid_sz, seed=None):\n",
    "    \"Take randoms subsets of `splits` with `train_sz` and `valid_sz`\"\n",
    "    assert 0 < train_sz < 1\n",
    "    assert 0 < valid_sz < 1\n",
    "    assert train_sz + valid_sz <= 1.\n",
    "\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        train_len,valid_len = int(len(o)*train_sz),int(len(o)*valid_sz)\n",
    "        idxs = L(int(i) for i in torch.randperm(len(o)))\n",
    "        return idxs[:train_len],idxs[train_len:train_len+valid_len]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(100))\n",
    "valid_idx = list(np.arange(70,100))\n",
    "splits = RandomSubsetSplitter(0.3, 0.1)(items)\n",
    "test_eq(len(splits[0]), 30)\n",
    "test_eq(len(splits[1]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        res = self.matcher(str(o))\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{os.path.sep}(\\d){os.path.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader():\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    store_attrs = 'cols'\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr(self, 'suff,label_delim')\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else r[c] if c=='name' else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        if len(self.cols) == 1: return self._do_one(o, self.cols[0])\n",
    "        return L(self._do_one(o, c) for c in self.cols)\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"ColReader -- {attrdict(self, *self.store_attrs.split(','))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [L('0a1', '0a1'), L('0b1', '0b1'), L('0c1', '0c1'), L('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])\n",
    "\n",
    "df['name'] = df['a']\n",
    "f = ColReader('name')\n",
    "test_eq([f(df.iloc[0,:])], [L(0,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False, strict=False):\n",
    "        if is_categorical_dtype(col):\n",
    "            items = L(col.cat.categories, use_list=True)\n",
    "            #Remove non-used categories while keeping order\n",
    "            if strict: items = L(o for o in items if o in col.unique())\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col, strict=True)\n",
    "test_eq(t, ['H','M'])\n",
    "test_eq(t.o2i, {'H':0,'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order,store_attrs=CrossEntropyLossFlat(),1,'vocab,add_na'\n",
    "    def __init__(self, vocab=None, sort=True, add_na=False):\n",
    "        store_attr(self, self.store_attrs+',sort')\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, sort=sort, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, sort=self.sort, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {attrdict(self, *self.store_attrs.split(','))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(vocab=['dog', 'cat'], sort=False, add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'dog', 'cat'])\n",
    "test_eq(cat('dog'), 1)\n",
    "test_eq(cat.decode(2), 'cat')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False): super().__init__(vocab,add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not dsets: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsets: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], TensorMultiCategory([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order,store_attrs=2,'c'\n",
    "    def __init__(self, c=None):\n",
    "        self.c = c\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.c is None: self.c = len(L(getattr(dsets, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {attrdict(self, *self.store_attrs.split(','))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab):\n",
    "        super().__init__(vocab)\n",
    "        self.c = len(vocab)\n",
    "    def encodes(self, o): return TensorMultiCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorMultiCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncodedMultiCategorize: {'vocab': (#3) ['a','b','c'], 'add_na': False}: (object,object) -> encodes (object,object) -> decodes"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RegressionSetup(Transform):\n",
    "    \"Transform that floatifies targets\"\n",
    "    loss_func,store_attrs=MSELossFlat(),'c'\n",
    "    def __init__(self, c=None):\n",
    "        self.c = c\n",
    "\n",
    "    def encodes(self, o): return tensor(o).float()\n",
    "    def decodes(self, o): return TitledFloat(o) if o.ndim==0 else TitledTuple(o_.item() for o_ in o)\n",
    "    def setups(self, dsets):\n",
    "        if self.c is not None: return\n",
    "        try: self.c = len(dsets[0]) if hasattr(dsets[0], '__len__') else 1\n",
    "        except: self.c = 0\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {attrdict(self, *self.store_attrs.split(','))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = RegressionSetup()\n",
    "dsets = Datasets([0, 1, 2], RegressionSetup)\n",
    "test_eq(dsets.c, 1)\n",
    "test_eq_type(dsets[0], (tensor(0.),))\n",
    "\n",
    "dsets = Datasets([[0, 1, 2], [3,4,5]], RegressionSetup)\n",
    "test_eq(dsets.c, 3)\n",
    "test_eq_type(dsets[0], (tensor([0.,1.,2.]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dls):\n",
    "    if getattr(dls, 'c', False): return dls.c\n",
    "    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c\n",
    "    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c\n",
    "    vocab = getattr(dls, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `Datasets`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/home/ml1/.fastai/data/mnist_tiny/train/7/934.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/8845.png'),Path('/home/ml1/.fastai/data/mnist_tiny/train/7/7731.png')],\n",
       " (#3) [Path('/home/ml1/.fastai/data/mnist_tiny/valid/7/8321.png'),Path('/home/ml1/.fastai/data/mnist_tiny/valid/7/9576.png'),Path('/home/ml1/.fastai/data/mnist_tiny/valid/7/79.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = Datasets(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACQUlEQVR4nO2bsW4aQRRFz0Tpkg9I5SoSfENa/gBS2z18TrT0SRvBD0RUyUdA5dpuk9YaF9EY52oN68g782TdI62wtmCHw92382ZMyjljjrxpPYBoWIhgIYKFCBYiWIhgIUJzISmlP3LcpZS+tBrP21YXLuSc35e/U0rvgBvge6vxNE+I8Bm4BX62GkA0IVfAt9ywn0hRepmU0gVwDXzMOV+3GkekhFwCv1rKgHhCvrYeRIhbJqX0CfgBfMg5/245ligJuQK2rWVAkIREIkpCwmAhgoUIFiKca+5ec8VNfSedEMFCBAsRLESwEMFCBAsRLESwEKH5NkRhvV4DsNvtANhutwDM53MANptNlXE4IcK5BaIX6WUWiwVw/Na7rgNgtVoNfo8RFrLcywyhSQ3RZJQ6AccUFUqaauGECFVqyHNI6d9be7/fAzCZTF78Un0nnRAh3DxEGSEZJ3FChDA1RGvHwwDG20hzDRlCmBqi1J5/FJwQwUIEC1FyzqeOKnRdl/n7RHs4KtD7mcMV1VbFtOBbRggh5DkLRWMTQkgkmtaQw+HQ8vK9OCFC1YSURJSthvL6mL5zALPZDBh/OcAJEaq0/2Xx53+eJmVeMkJC3P4PoUoNWS6XvecfJ6b2luVTOCFC1afMqaSUGtEaJ0SwEMFChDDrIeWJU2tG+hROiBAmIYXSyzghQWi6lVm63+l0erxgvd8AupcZQpjN7gY4IUOwEMFCBAsRLEQ4N1Pt/z+nV4wTIliIYCGChQgWIliIcA/vwoxpOFM4+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order,store_attrs = 10,'div,div_mask' #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1):\n",
    "        store_attr(self, 'div,div_mask')\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.long() // self.div_mask\n",
    "    def decodes(self, o:TensorImage): return ((o.clamp(0., 1.) * self.div).long()) if self.div else o\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {attrdict(self, *self.store_attrs.split(','))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor()\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    parameters,order,store_attrs=L('mean', 'std'),99, 'mean,std,axes'\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)):\n",
    "        self.mean,self.std,self.axes = mean,std,axes\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "\n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch()\n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {attrdict(self, *self.store_attrs.split(','))}\"\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor(), Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.LongTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.float().mean()/255.<1\n",
    "assert 0<xd.float().std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 18a_callback.training.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.text.ipynb.\n",
      "Converted 39_tutorial.transformers.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 44_tutorial.tabular.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 46_tutorial.collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 73_callback.captum.ipynb.\n",
      "Converted 74_callback.cutmix.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
